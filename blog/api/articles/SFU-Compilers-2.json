{"title":"SFU Compilers class 笔记2","uid":"b8be4bf58b4cb3abe70be3d848e17901","slug":"SFU-Compilers-2","date":"2022-03-15T04:00:00.000Z","updated":"2022-07-10T14:24:40.269Z","comments":true,"path":"api/articles/SFU-Compilers-2.json","keywords":null,"cover":[],"content":"<h1 id=\"SFU-Compilers-笔记2-词法分析\"><a href=\"#SFU-Compilers-笔记2-词法分析\" class=\"headerlink\" title=\"SFU Compilers 笔记2 词法分析\"></a>SFU Compilers 笔记2 词法分析</h1><p>week2 wee3 p-lex hw1</p>\n<h2 id=\"Week-2-Lexical-Analysis-1\"><a href=\"#Week-2-Lexical-Analysis-1\" class=\"headerlink\" title=\"Week 2 Lexical Analysis 1\"></a>Week 2 Lexical Analysis 1</h2><h3 id=\"LEX1-Intro-to-Regexps\"><a href=\"#LEX1-Intro-to-Regexps\" class=\"headerlink\" title=\"LEX1 Intro to Regexps\"></a>LEX1 Intro to Regexps</h3><p><strong>词法分析</strong></p>\n<p>将字符串转成tokens</p>\n<p><strong>Token Attributes</strong></p>\n<p>具有属性的例子：<code>T_IDENT (&quot;sqrt&quot;)</code>,<code>T_INTCONSTANT (&quot;1&quot;)</code></p>\n<p>Token: <code>T_IDENT</code><br>Lexeme: <code>(&quot;sqrt&quot;)</code></p>\n<p>不具有属性的例子：<code>T_WHILE</code></p>\n<p><strong>实现Lexers：循环和swich扫描器</strong></p>\n<ul>\n<li>大量嵌套switch/case</li>\n<li>大量getc()、ungetc()</li>\n<li>容易出错</li>\n<li>难以更改和添加关键字</li>\n</ul>\n<p>ad-hoc lexer源码：<a href=\"https://github.com/llvm/llvm-project/blob/3170d54842655d6d936aae32b7d0bc92fce7f22e/clang/lib/Lex/Lexer.cpp\">LexTokenInternal in clang</a></p>\n<p><strong>正则表达式</strong></p>\n<p>大概介绍了下正则表达式</p>\n<p>限制：在设计语言语法时要考虑正则语法，以便于构造正则表达式</p>\n<h3 id=\"LEX2-Regular-Expresssions\"><a href=\"#LEX2-Regular-Expresssions\" class=\"headerlink\" title=\"LEX2 Regular Expresssions\"></a>LEX2 Regular Expresssions</h3><p>Integer：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">digit &#x3D; (0|1|2|3|4|5|6|7|8|9)\n&#123;digit&#125;+</code></pre>\n\n<p>Identifier：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">digit &#x3D; [0-9]\nletter &#x3D; [a-zA-Z]\n\n&#123;letter&#125;(&#123;letter&#125;|&#123;digit&#125;)*</code></pre>\n\n<p>Whitespace：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">(&quot; &quot;|&quot;\\t&quot;|&quot;\\n&quot;)+</code></pre>\n\n<p>Pattern definition for numbers：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">digit &#x3D; [0-9]\ndigits &#x3D; [0-9]+\nopt_frac &#x3D; (&quot;.&quot;&#123;digits&#125;)?\nopt_exp &#x3D; ((e|E)(\\+|\\-)?&#123;digits&#125;)?\nnum &#x3D; &#123;digits&#125;&#123;opt_frac&#125;&#123;opt_exp&#125;\n\n345, 345.04 , 2e-7, 2e7, 2e+7, 3.14e5</code></pre>\n\n\n\n<p>优先级：</p>\n<ul>\n<li>匹配长度</li>\n<li>token顺序</li>\n</ul>\n<h2 id=\"Week-3-Lexical-Analysis-2\"><a href=\"#Week-3-Lexical-Analysis-2\" class=\"headerlink\" title=\"Week 3 Lexical Analysis 2\"></a>Week 3 Lexical Analysis 2</h2><h3 id=\"LEX3-Regexps-are-Trees\"><a href=\"#LEX3-Regexps-are-Trees\" class=\"headerlink\" title=\"LEX3 Regexps are Trees\"></a>LEX3 Regexps are Trees</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>参考链接：</p>\n<p><a href=\"https://xkcd.com/208/\">xkcd: Regular Expressions</a></p>\n<p>有点类似于NFA的可视化：</p>\n<p><a href=\"https://www.debuggex.com/\">Debuggex: Online visual regex tester. JavaScript, Python, and PCRE.</a></p></blockquote>\n<p><strong>正则优先级</strong>：</p>\n<ol>\n<li>()</li>\n<li>一元运算符（unary op.）</li>\n<li>用于连接的二元运算符（binary op. for concatenation）</li>\n<li>间隔的二元运算符（binary op. for alternation）</li>\n</ol>\n<p><strong>正则表达式是一树</strong></p>\n<p>使用左结合来得到唯一的树</p>\n<p><strong>等价的正则表达式</strong></p>\n<p>可以化简正则表达式</p>\n<p>一些性质：</p>\n<ul>\n<li>结合律（Commutative，可交换的）</li>\n<li>分配律</li>\n<li>交换律</li>\n<li>R | R == R</li>\n<li>R*R* == (R*)* == RR*|e == R*</li>\n</ul>\n<h3 id=\"LEX4-Regexps-as-Automata\"><a href=\"#LEX4-Regexps-as-Automata\" class=\"headerlink\" title=\"LEX4 Regexps as Automata\"></a>LEX4 Regexps as Automata</h3><p>主要讲了有限状态机（FSA）、DFA、NFA的概念</p>\n<p>还有NFA到DFA的转换思路</p>\n<p><strong>DFA</strong></p>\n<p>对于一个输入，其路径唯一，若能到达终点则为合法</p>\n<p><strong>NFA</strong></p>\n<p>对于一个输入，可能有多条路径，只要有一条能到达终点则为合法</p>\n<p><strong>NFA 转 DFA</strong></p>\n<p>把NFA状态的组合，当成DFA的状态</p>\n<p><strong>DFA vs NFA</strong></p>\n<ul>\n<li>DFA不允许有歧义</li>\n<li>DFA不允许无条件转移</li>\n<li>DFA执行速度更快（NFA存在歧义可能需要搜索）</li>\n<li>DFA通常情况状态比NFA少</li>\n<li>最坏情况DFA的状态比NFA多（2的n次方倍，n为NFA的状态数量）</li>\n</ul>\n<h3 id=\"LEX5-Regexps-to-NFA\"><a href=\"#LEX5-Regexps-to-NFA\" class=\"headerlink\" title=\"LEX5 Regexps to NFA\"></a>LEX5 Regexps to NFA</h3><p><strong>Thompson构造法</strong></p>\n<ul>\n<li>Rule0（empty language）  <img src=\"E:\\documents\\note\\md\\笔记\\ThompsonRule0.jpg\" style=\"zoom:50%;\" /></li>\n<li>Rule1（x）  <img src=\"E:\\documents\\note\\md\\笔记\\ThompsonRule1.jpg\" style=\"zoom:50%;\" /></li>\n<li>Rule2（empty string，ε）  <img src=\"E:\\documents\\note\\md\\笔记\\ThompsonRule2.jpg\" style=\"zoom:50%;\" /></li>\n<li>Rule3（r1 | r2）  <img src=\"E:\\documents\\note\\md\\笔记\\ThompsonRule3.jpg\" style=\"zoom:50%;\" /></li>\n<li>Rule4（r1r2）  <img src=\"E:\\documents\\note\\md\\笔记\\ThompsonRule4.jpg\" style=\"zoom:50%;\" /></li>\n<li>Rule5（r*）  <img src=\"E:\\documents\\note\\md\\笔记\\ThompsonRule5.jpg\" style=\"zoom:50%;\" />\n\n\n\n</li>\n</ul>\n<p>按照正则表达式树的后序遍历的顺序，根据Rule构造NFA</p>\n<h3 id=\"lex6-NFA-to-DFA（todo）\"><a href=\"#lex6-NFA-to-DFA（todo）\" class=\"headerlink\" title=\"lex6 NFA to DFA（todo）\"></a>lex6 NFA to DFA（todo）</h3><p><strong>ε-closure</strong></p>\n<p>ε-closure(s) = {s以及s开始所有能通过ε到达的点}</p>\n<p><strong>转换</strong></p>\n<p>（NFA中大写是状态的集合，小写是单个状态）</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>NFA</th>\n<th>DFA</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>States</td>\n<td>S</td>\n<td>{X | X ⊆ S}</td>\n</tr>\n<tr>\n<td>start</td>\n<td>q ∈ S</td>\n<td>ε-closure(q)</td>\n</tr>\n<tr>\n<td>Final</td>\n<td>F ⊆ S</td>\n<td>{X | X∩F ≠ ø}</td>\n</tr>\n<tr>\n<td>transition</td>\n<td>δ(x,a) = y</td>\n<td>δ(X,a) = ε-closure(δ(x,a)), x∈X</td>\n</tr>\n</tbody></table>\n<p><strong>最小化DFA</strong></p>\n<p>合并所有转移条件及目标相同的点</p>\n<p>对所有a，δ(X,a) = δ(Y,a)，合并X、Y</p>\n<p><strong>NFA to DFA</strong></p>\n<p>// todo</p>\n<pre class=\"line-numbers language-pascal\" data-language=\"pascal\"><code class=\"language-pascal\">states[0] &#x3D; e-closure(&#123;q0&#125;)\np &#x3D; j &#x3D; 0\nwhile j &lt;&#x3D; p do\n\tfor each symbol c do\n\t\te &#x3D; DFAedge(states[j], c)\n\t\tif e &#x3D;&#x3D; states[i] for some i &lt;&#x3D; p\n\t\tthen Dtrans[j, c] &#x3D; i\n\t\telse\n\t\t\tp &#x3D; p+1\n\t\t\tstates[p] &#x3D; e\n\t\t\tDtrans[j,c] &#x3D; p\n    j &#x3D; j+1</code></pre>\n\n\n\n<h3 id=\"lex7-NFA-to-DFA-Complexity（pass）\"><a href=\"#lex7-NFA-to-DFA-Complexity（pass）\" class=\"headerlink\" title=\"lex7 NFA to DFA Complexity（pass）\"></a>lex7 NFA to DFA Complexity（pass）</h3><p>pass</p>\n<h3 id=\"LEX8-Lexical-Analyzer\"><a href=\"#LEX8-Lexical-Analyzer\" class=\"headerlink\" title=\"LEX8 Lexical Analyzer\"></a>LEX8 Lexical Analyzer</h3><p><strong>使用DFA的词法分析</strong></p>\n<ul>\n<li>每个token定义成一个正则表达式</li>\n<li>合并所有正则表达式成一个大的正则表达式</li>\n<li>转换成NFA，DFA，最小化</li>\n<li>DFA识别器必须找到左边一个匹配长度最长的token</li>\n<li>如果两个匹配的token的长度相同的，优先选择token列表中更前面的</li>\n</ul>\n<p><strong>Lookahead operator</strong></p>\n<p>r1后面必须跟着r2</p>\n<p>匹配r1εr2，并记录下r1和r2结束的位置</p>\n<p><strong>总结</strong></p>\n<ul>\n<li>Token =&gt; Pattern (LEX2)</li>\n<li>Pattern =&gt; Regular Expression (LEX2)</li>\n<li>Regular Expression =&gt; NFA (LEX5)<ul>\n<li>Thompson’s Rules</li>\n</ul>\n</li>\n<li>NFA =&gt; DFA (LEX4, lex6, lex7)<ul>\n<li>Subset construction</li>\n<li>DFA =&gt; minimal DFA</li>\n</ul>\n</li>\n<li>DFA =&gt; Table-driven implementation of DFA (lex9)</li>\n</ul>\n<h3 id=\"lex9-Implementing-DFAs\"><a href=\"#lex9-Implementing-DFAs\" class=\"headerlink\" title=\"lex9 Implementing DFAs\"></a>lex9 Implementing DFAs</h3><p><strong>使用二维数组存储转移表</strong></p>\n<p>T[state_idx, input_symbol] = next_state_idx</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">i &#x3D; 0;\nstate &#x3D; 0;\nwhile(input[i]) &#123;\n    state &#x3D; T[state, input[i]];\n    i++;\n&#125;</code></pre>\n\n\n\n<p><strong>压缩转移表</strong></p>\n<p>二维数组占用空间大，且有很多重复元素；链表查询速度慢</p>\n<p>一种解决办法是压缩二维数组，二维数组中有空位（T[i,a]=None），利用这些空位存储信息</p>\n<p>再用一个额外的数组记录新表中每一格所属的状态</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">&#x2F;&#x2F; origin\nnext_state &#x3D; T[state, input[i]];\n&#x2F;&#x2F; sparse tables\nidx &#x3D; B[state] + a\nnext_state &#x3D; check[idx] &#x3D;&#x3D; state ? ST[idx] : -1</code></pre>\n\n\n\n<p>示例：</p>\n<table>\n<thead>\n<tr>\n<th>T(s\\a)</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n<th>d</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>0</td>\n<td>-</td>\n<td>1</td>\n<td>-</td>\n<td>2</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1</td>\n<td>-</td>\n<td>1</td>\n<td>-</td>\n</tr>\n<tr>\n<td>2</td>\n<td>1</td>\n<td>2</td>\n<td>1</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th>Base(s\\i)</th>\n<th>idx</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>0</td>\n<td>2</td>\n</tr>\n<tr>\n<td>1</td>\n<td>4</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0</td>\n</tr>\n</tbody></table>\n<table>\n<thead>\n<tr>\n<th>idx</th>\n<th>0</th>\n<th>1</th>\n<th>2</th>\n<th>3</th>\n<th>4</th>\n<th>5</th>\n<th>6</th>\n<th>7</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>s_0</td>\n<td></td>\n<td></td>\n<td>-</td>\n<td>1</td>\n<td>-</td>\n<td>2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>s_1</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td>1</td>\n<td>-</td>\n<td>1</td>\n<td>-</td>\n</tr>\n<tr>\n<td>s_2</td>\n<td>1</td>\n<td>2</td>\n<td>1</td>\n<td>-</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>ST[]</td>\n<td>1</td>\n<td>2</td>\n<td>1</td>\n<td>1</td>\n<td>1</td>\n<td>2</td>\n<td>1</td>\n<td>-</td>\n</tr>\n<tr>\n<td>check[]</td>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h3 id=\"lex10-Regexp-to-DFA（pass）\"><a href=\"#lex10-Regexp-to-DFA（pass）\" class=\"headerlink\" title=\"lex10 Regexp to DFA（pass）\"></a>lex10 Regexp to DFA（pass）</h3><p>pass</p>\n<h2 id=\"Practice-Lex\"><a href=\"#Practice-Lex\" class=\"headerlink\" title=\"Practice Lex\"></a>Practice Lex</h2><h3 id=\"Regexp\"><a href=\"#Regexp\" class=\"headerlink\" title=\"Regexp\"></a><strong>Regexp</strong></h3><p>让Σ = {0, 1}</p>\n<ol>\n<li>集合的元素个数：2</li>\n<li>Σ3（三次方）：{000, 001, … , 110, 111}</li>\n<li>Σ*：Σ0 + Σ1 + Σ2 + …</li>\n<li>Σ*中所有等于十进制数字6的regexp：<code>0*110</code></li>\n<li>Σ*中所有2的幂的regexp：<code>10*</code></li>\n<li>Σ*中所有偶数的regexp：<code>[0|1]*0</code></li>\n<li>Σ*中所有BCD码（包括空字符串）的regexp：<code>((0[01][01][01])|(100[01]))* </code></li>\n</ol>\n<p><code>(0[01][01][01])</code>=0<del>7，<code>(100[01]))</code>=8</del>9</p>\n<h3 id=\"Simple-Tokenizer\"><a href=\"#Simple-Tokenizer\" class=\"headerlink\" title=\"Simple Tokenizer\"></a>Simple Tokenizer</h3><pre class=\"line-numbers language-shell\" data-language=\"shell\"><code class=\"language-shell\">apt install make\napt install flex\n\nmake simpletok\n# compiling lex file: simpletok.lex\n# output file: simpletok\n# flex -osimpletok.c simpletok.lex\n# gcc -o .&#x2F;simpletok simpletok.c -ll\n# &#x2F;bin&#x2F;rm -f simpletok.c\n\n.&#x2F;simpletok\n90int  # type this in yourself upto the comment char\n# IDENTIFIER: 90int, LENGTH:5\nCtrl-D # this terminates the standard input stream</code></pre>\n\n\n\n<h3 id=\"Lexical-Analysis\"><a href=\"#Lexical-Analysis\" class=\"headerlink\" title=\"Lexical Analysis\"></a>Lexical Analysis</h3><p>要求手动预测一组token的识别结果</p>\n<p>计算答案的lex代码在<code>tokenizer2.lex</code></p>\n<p>Provide the tokenized output for the following input strings using the greedy longest match lexical analysis method. Provide the list of tokens and the lexeme values.</p>\n<h3 id=\"Lexical-Analysis-using-lex\"><a href=\"#Lexical-Analysis-using-lex\" class=\"headerlink\" title=\"Lexical Analysis using lex\"></a>Lexical Analysis using <code>lex</code></h3><p>要求使用lex实现一组token的识别</p>\n<p>标准答案在<code>tokenizer.lex</code></p>\n<h3 id=\"Remove-Multi-line-Comments\"><a href=\"#Remove-Multi-line-Comments\" class=\"headerlink\" title=\"Remove Multi-line Comments\"></a>Remove Multi-line Comments</h3><p>目录：<code>rmcomments</code></p>\n<p>匹配c语言风格多行注释</p>\n<p>正则表达式：<code>\\/\\*((?!\\*\\/).|\\n)*\\*\\/</code></p>\n<p>lex不支持向前匹配的<code>?!</code>：</p>\n<p>lex写法：<code>\\/\\*(\\n|[^*]|[*]*[^*/])*[*]*\\*\\/</code></p>\n<p>构造过程：</p>\n<p>regexp_1：<code>\\/\\*[^*]*\\*\\/</code>，匹配非<code>*</code>字符（r1=<code>[^*]</code>）</p>\n<p>能够匹配类型1：<code>/* 123 */</code>，无法匹配类型2的<code>***/</code>结尾的情况</p>\n<p>regexp_2：<code>\\/\\*[^*]*[*]*\\*\\/</code>（r2=<code>[*]*</code>）</p>\n<p>能够匹配类型2：<code>/* 123 *****/</code>，无法匹配类型3的中间有<code>*****</code>+非<code>*</code>字符的情况</p>\n<p>regexp_3：<code>[*]*[^*/]</code>，用于匹配多个<code>*</code>接一个非<code>*</code>且非<code>/</code>的情况（r3=<code>[*]*[^*/]</code>）</p>\n<p>类型3：<code>/* ***** */ </code></p>\n<p>结合到一起：<code>\\/\\*(\\n|&#123;r1&#125;|&#123;r3&#125;)*&#123;r2&#125;\\*\\/</code></p>\n<p>最终方案：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">%%\n\\&quot;[^\\&quot;]*\\&quot;  ECHO;\n\\&#x2F;\\&#x2F;.*\t\t&#123; &#125;\n\\&#x2F;\\*(\\n|[^*]|[*]*[^*&#x2F;])*[*]*\\*\\&#x2F;  &#123; &#125;\n.|\\n\tECHO;\n%%</code></pre>\n\n\n\n<p>其他忽略多行注释的解决方案：</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">%%\n\\&#x2F;\\*    comment();\n%%\n\ncomment() &#123;\n    char c0, c1;\nloop:\n    while((c0 &#x3D; input()) !&#x3D; &#39;*&#39; &amp;&amp; c0 !&#x3D; 0) &#123;\n        &#x2F;&#x2F; putchar(c0);\n    &#125;\n    \n    if ((c1 &#x3D; input()) !&#x3D; &#39;&#x2F;&#39; &amp;&amp; c0 !&#x3D; 0) &#123;\n        unput(c1);\n        goto loop;\n    &#125;\n\n    &#x2F;&#x2F; if(c0 !&#x3D; 0) putchar(c0);\n&#125;</code></pre>\n\n\n\n<h3 id=\"Matching-a-Right-Context\"><a href=\"#Matching-a-Right-Context\" class=\"headerlink\" title=\"Matching a Right Context\"></a>Matching a Right Context</h3><p>要求手动预测一组右上下文相关的token的识别结果</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">%%\na*b+&#x2F;c+  &#123; printf(&quot;T_AB:%s\\n&quot;, yytext); &#125;\n%%</code></pre>\n\n\n\n<h3 id=\"Matching-a-Left-Context\"><a href=\"#Matching-a-Left-Context\" class=\"headerlink\" title=\"Matching a Left Context\"></a>Matching a Left Context</h3><p>要求实现左上下文相关的token的识别</p>\n<p>标准答案在<code>leftcontext.lex</code>，需要修改makefile以编译该代码</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">%%\noutputfile      BEGIN OUTPUT;\n&lt;OUTPUT&gt;\\&quot;.*\\&quot;  &#123; BEGIN 0; ECHO; printf(&quot; is the output file.\\n&quot;); &#125;\n%%</code></pre>\n\n\n\n<h3 id=\"Backtracking-in-Lex（todo）\"><a href=\"#Backtracking-in-Lex（todo）\" class=\"headerlink\" title=\"Backtracking in Lex（todo）\"></a>Backtracking in Lex（todo）</h3><p>// todo</p>\n<h3 id=\"Counting-with-Lex（todo）\"><a href=\"#Counting-with-Lex（todo）\" class=\"headerlink\" title=\"Counting with Lex（todo）\"></a>Counting with Lex（todo）</h3><p>// todo</p>\n<h2 id=\"Homework-1-Lexical-Analysis\"><a href=\"#Homework-1-Lexical-Analysis\" class=\"headerlink\" title=\"Homework 1 Lexical Analysis\"></a>Homework 1 Lexical Analysis</h2><p>前置条件：hw0、lex-practice</p>\n<p>目录：<code>decaflex</code></p>\n<p><code>./answer/default.lex</code>为未完成的作业，复制为<code>./answer/decaflex.lex</code>并完成</p>\n<p><strong>规则编写</strong></p>\n<p>参照语言的定义编写即可</p>\n<p>把<code>Keywords</code>的定义放到最前面，不然会无法识别，其余按字母顺序好像也没问题</p>\n<p>注意输出要求，对于<code>[\\n\\v\\f]</code>要求输出其转义序列，而不是转义后的字符，<code>\\r\\n</code>（CRLF）输出一个<code>\\n</code>即可</p>\n<p>即对于<code>T_WHITESPACE</code>，忽略<code>\\r</code>，为了简便直接循环处理：</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">case T_WHITESPACE: &#123;\n    cout &lt;&lt; &quot;T_WHITESPACE &quot;;\n    for (i &#x3D; 0; i &lt; yyleng; i++)&#123;\n        switch(yytext[i])&#123;\n            case 9: cout &lt;&lt; &quot;\\t&quot;; break;\n            case 10: cout &lt;&lt; &quot;\\\\n&quot;; break;\n            case 11: cout &lt;&lt; &quot;\\\\v&quot;; break;\n            case 12: cout &lt;&lt; &quot;\\\\f&quot;; break;\n            case 13: &#x2F;*cout &lt;&lt; &quot;\\\\r&quot;;*&#x2F; break;\n            case 32: cout &lt;&lt; &quot; &quot;; break;\n        &#125;\n    &#125;\n    cout &lt;&lt; endl;\n    break;\n&#125;</code></pre>\n\n\n\n<p>对于<code>T_COMMENT</code>，其正则表达式为<code>\\/\\/.*[\\n]</code>，简便处理，默认是CRLF：</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">case T_COMMENT: &#123;\n    lexeme[yyleng-2] &#x3D; &#39;\\\\&#39;;\n    lexeme[yyleng-1] &#x3D; &#39;n&#39;;\n    cout &lt;&lt; &quot;T_COMMENT &quot; &lt;&lt; lexeme &lt;&lt; endl;\n    break;\n&#125;</code></pre>\n\n","feature":true,"text":"SFU Compilers 笔记2 词法分析week2 wee3 p-lex hw1 Week 2 Lexical Analysis 1LEX1 Intro to Regexps词法分析 将字符串转成tokens Token Attributes 具有属性的例子：T_IDENT ...","link":"","photos":[],"count_time":{"symbolsCount":"7.1k","symbolsTime":"6 mins."},"categories":[{"name":"CS","slug":"CS","count":3,"path":"api/categories/CS.json"}],"tags":[{"name":"note","slug":"note","count":21,"path":"api/tags/note.json"},{"name":"cs","slug":"cs","count":3,"path":"api/tags/cs.json"},{"name":"compiler","slug":"compiler","count":3,"path":"api/tags/compiler.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#SFU-Compilers-%E7%AC%94%E8%AE%B02-%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90\"><span class=\"toc-text\">SFU Compilers 笔记2 词法分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Week-2-Lexical-Analysis-1\"><span class=\"toc-text\">Week 2 Lexical Analysis 1</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LEX1-Intro-to-Regexps\"><span class=\"toc-text\">LEX1 Intro to Regexps</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LEX2-Regular-Expresssions\"><span class=\"toc-text\">LEX2 Regular Expresssions</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Week-3-Lexical-Analysis-2\"><span class=\"toc-text\">Week 3 Lexical Analysis 2</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LEX3-Regexps-are-Trees\"><span class=\"toc-text\">LEX3 Regexps are Trees</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LEX4-Regexps-as-Automata\"><span class=\"toc-text\">LEX4 Regexps as Automata</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LEX5-Regexps-to-NFA\"><span class=\"toc-text\">LEX5 Regexps to NFA</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#lex6-NFA-to-DFA%EF%BC%88todo%EF%BC%89\"><span class=\"toc-text\">lex6 NFA to DFA（todo）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#lex7-NFA-to-DFA-Complexity%EF%BC%88pass%EF%BC%89\"><span class=\"toc-text\">lex7 NFA to DFA Complexity（pass）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LEX8-Lexical-Analyzer\"><span class=\"toc-text\">LEX8 Lexical Analyzer</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#lex9-Implementing-DFAs\"><span class=\"toc-text\">lex9 Implementing DFAs</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#lex10-Regexp-to-DFA%EF%BC%88pass%EF%BC%89\"><span class=\"toc-text\">lex10 Regexp to DFA（pass）</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Practice-Lex\"><span class=\"toc-text\">Practice Lex</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Regexp\"><span class=\"toc-text\">Regexp</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Simple-Tokenizer\"><span class=\"toc-text\">Simple Tokenizer</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Lexical-Analysis\"><span class=\"toc-text\">Lexical Analysis</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Lexical-Analysis-using-lex\"><span class=\"toc-text\">Lexical Analysis using lex</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Remove-Multi-line-Comments\"><span class=\"toc-text\">Remove Multi-line Comments</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Matching-a-Right-Context\"><span class=\"toc-text\">Matching a Right Context</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Matching-a-Left-Context\"><span class=\"toc-text\">Matching a Left Context</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Backtracking-in-Lex%EF%BC%88todo%EF%BC%89\"><span class=\"toc-text\">Backtracking in Lex（todo）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Counting-with-Lex%EF%BC%88todo%EF%BC%89\"><span class=\"toc-text\">Counting with Lex（todo）</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Homework-1-Lexical-Analysis\"><span class=\"toc-text\">Homework 1 Lexical Analysis</span></a></li></ol></li></ol>","author":{"name":"御史神风","slug":"御史神风","avatar":"/blog/imgs/child.jpg","link":"/","description":"芜湖~好耶!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"SFU Compilers class 笔记3","uid":"a1035c3663b3c14e4c1a5b534fff7e3d","slug":"SFU-Compilers-3","date":"2022-05-09T04:00:00.000Z","updated":"2022-07-10T14:24:53.207Z","comments":true,"path":"api/articles/SFU-Compilers-3.json","keywords":null,"cover":[],"text":"SFU Compilers 笔记 3 语法分析w4 p:yacc w5 w6 Week 4 Context-Free Grammars（lost）CFG1 Intro to CFGs一个CFG包括： 终止符集合：T（输入符号） 非终止符集合：N 开始符号：S ∈ N 规则集合 应...","link":"","photos":[],"count_time":{"symbolsCount":"4.7k","symbolsTime":"4 mins."},"categories":[{"name":"CS","slug":"CS","count":3,"path":"api/categories/CS.json"}],"tags":[{"name":"note","slug":"note","count":21,"path":"api/tags/note.json"},{"name":"cs","slug":"cs","count":3,"path":"api/tags/cs.json"},{"name":"compiler","slug":"compiler","count":3,"path":"api/tags/compiler.json"}],"author":{"name":"御史神风","slug":"御史神风","avatar":"/blog/imgs/child.jpg","link":"/","description":"芜湖~好耶!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"《逆向工程实战》实例D","uid":"59b8a2ac42b98d74611bef705cd30176","slug":"practicalreD","date":"2022-03-11T04:00:00.000Z","updated":"2022-04-13T13:58:55.515Z","comments":true,"path":"api/articles/practicalreD.json","keywords":null,"cover":null,"text":"《逆向工程实战》实例D摘要基本信息 x86 Device Name：\\Device\\ProcPanama SymbolLink Name：\\DosDevices\\ProcPanama IRP：Create、Close、DeviceIoCtrl 回调：进程 函数分析结果 sub_1...","link":"","photos":[],"count_time":{"symbolsCount":"5.1k","symbolsTime":"5 mins."},"categories":[{"name":"Windows","slug":"Windows","count":18,"path":"api/categories/Windows.json"}],"tags":[{"name":"windows","slug":"windows","count":18,"path":"api/tags/windows.json"},{"name":"note","slug":"note","count":21,"path":"api/tags/note.json"},{"name":"practicalre","slug":"practicalre","count":5,"path":"api/tags/practicalre.json"}],"author":{"name":"御史神风","slug":"御史神风","avatar":"/blog/imgs/child.jpg","link":"/","description":"芜湖~好耶!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}